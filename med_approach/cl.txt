Chapter 25

Computational linguistics and grammar
engineering
Emily M. Bender
University of Washington

Guy Emerson
University of Cambridge

We discuss the relevance of HPSG for computational linguistics, and the relevance
of computational linguistics for HPSG, including: the theoretical and computational infrastructure required to carry out computational studies with HPSG; computational resources developed within HPSG; how those resources are deployed,
for both practical applications and linguistic research; and finally, a sampling of linguistic insights achieved through HPSG-based computational linguistic research.

1 Introduction
From the inception of HPSG in the 1980s, there has been a close integration between theoretical and computational work (for an overview, see Flickinger, Pollard & Wasow 2020, Chapter 2 of this volume). In this chapter, we discuss computational work in HPSG, starting with the infrastructure that supports it (both
theoretical and practical) in Section 2. Next we describe several existing largescale projects which build HPSG or HPSG-inspired grammars (see Section 3) and
the deployment of such grammars in applications including both those within
linguistic research and otherwise (see Section 4). Finally, we turn to linguistic
insights gleaned from broad-coverage grammar development (see Section 5).

2 Infrastructure

2.1 Theoretical considerations

There are several properties of HPSG as a theory that make it well-suited to computational implementation. First, the theory is kept separate from the formalism:
the formalism is expressive enough to encode a wide variety of possible theories.
While some theoretical work does argue for or against the necessity of particular formal devices (e.g., the shuffle operator; Reape 1994), much of it proceeds
within shared assumptions about the formalism. This is in contrast to work in
the context of the Minimalist Program (Chomsky 1995), where theoretical results
are typically couched in terms of modifications to the formalism itself. From a
computational point of view, the benefit of differentiating between theory and
formalism is that the formalism is relatively stable. That enables the development and maintenance of software systems that target the formalism (Boguraev
et al. 1988), such as software for parsing, generation, and grammar exploration
(see Section 3 below for some examples).1
A second important property of HPSG that supports a strong connection between theoretical and computational work is an interest in both so-called ‚Äúcore‚Äù
and so-called ‚Äúperipheral‚Äù phenomena. Most implemented grammars are built
with the goal of handling naturally occurring text.2 This means that they will
need to handle a wide variety of linguistic phenomena not always treated in theoretical syntactic work (Baldwin et al. 2005). A syntactic framework that discounts
research on ‚Äúperipheral‚Äù phenomena as uninteresting provides less support for
implementational work than does one, like HPSG or Construction Grammar, that
values such topics (for a comparison of HPSG and Construction Grammar, see
M√ºller 2020b, Chapter 33 of this volume).
Finally, the type hierarchy characteristic of HPSG lends itself well to developing broad-coverage grammars which are maintainable over time (see Sygal
& Wintner 2011). The use of the type hierarchy to manage complexity at scale
comes out of the work of Flickinger (1987) and others at HP labs in the project
where HPSG was originally developed. The core idea is that any given constraint
is (ideally) expressed only once, on a type which serves as a supertype to all en1 There

are implementations of Minimalism, notably Stabler (1997) and Herring (2016). (See
also Torr et al. 2019 for a recent broad-coverage, treebank-trained parser in this framework.)
However, implementing a theory requires fixing the formalism, and so these implementations
are unlikely to be useful for testing theoretical ideas if the formalism moves on.
2 It is possible, but less common, to do implementation work strictly against test suites of sentences constructed specifically to focus on phenomena of interest.

tities that bear that constraint.3 Such constraints might represent broad generalizations that apply to many entities or relatively narrow, idiosyncratic properties
that apply to only a few. By isolating any given constraint on one type (as opposed to repeating it in multiple places), we build grammars that are easier to
update and adapt in light of new data that require refinements to constraints.
Having a single locus for each constraint also makes the types a very useful target for documentation (Hashimoto et al. 2008) and grammar exploration (Letcher
2018).

2.2 Practical considerations
HPSG allows practical implementations because it uses a well-defined formalism. Furthermore, because HPSG is defined to be bi-directional, an implemented
grammar can be used for both parsing and generation. In this section, we discuss
how HPSG allows tractable algorithms, which enables linguists to empirically
test hypotheses and which also enables HPSG grammars to be used in a range of
applications, as we will see in Sections 4.1 and 4.2, respectively.
2.2.1 Computational complexity
One way to measure how easy or difficult it is to use a syntactic theory in practical computational applications is to consider the computational complexity 4 of
parsing and generation algorithms (Gazdar & Pullum 1985). Computational complexity includes both how much memory and how much computational time a
parsing algorithm needs to process a particular sentence.5 Considering parsing
time, longer sentences will take longer to process, but the more complex the algorithm is, the more quickly the amount of processing time increases. Parsing
complexity can thus be measured by considering sentences containing ùëõ tokens,
and then increasing ùëõ to see how the amount of time changes. This can be done
3 Originally this only applied to lexical entries in Flickinger‚Äôs work. Now it also applies to phrase

structure rules, lexical rules, and types below the level of the sign which are used in the definition of all of these. See Flickinger, Pollard & Wasow (2020), Chapter 2 of this volume for
further discussion.
4 Computational complexity is related to the complexity hierarchy of language classes in formal
language theory. More complex language classes tend to require parsing and generation algorithms with higher computational complexity, but this relationship is not exact. For example,
the class of strictly local languages is a proper subset of the class of regular languages, but
both classes can be parsed in linear time. M√ºller (2019: Chapter 17) discusses HPSG from the
point of view of formal language theory.
5 In this section, we only consider parsing algorithms, but a similar analysis can be done for
generation (e.g., Carroll et al. 1999).

based on the average amount of time for sentences in a corpus (average-case
complexity), or based on the longest amount of time for all theoretically possible
sentences (worst-case complexity).
At first sight, analyzing computational complexity would seem to paint HPSG
in a bad light, because the formalism allows us to write grammars which can be
arbitrarily complex; in technical terminology, the formalism is Turing-complete
(Johnson 1988: Section 3.4). However, as discussed in the previous section, there
is a clear distinction between theory and formalism. Although the HPSG formalism rules out the possibility of efficient algorithms that could cope with any
possible feature-structure grammar, a particular theory (or a particular grammar)
might well allow efficient algorithms.
Keeping processing complexity manageable is handled differently in other
computationally-friendly frameworks, such as Combinatory Categorial Grammar (CCG),6 or Tree Adjoining Grammar (TAG; Joshi 1987; Schabes et al. 1988).
The formalisms of CCG and TAG inherently limit computational complexity:
for both of them, as the sentence length ùëõ increases, worst-case parsing time
is proportional to ùëõ 6 (Kasami et al. 1989). This is a deliberate feature of these
formalisms, which aim to be just expressive enough to capture human language,
and not any more expressive. Building this kind of constraint into the formalism
itself highlights a different school of thought from HPSG. Indeed, M√ºller (2015:
64) explicitly argues in favor of developing linguistic analyses first, and improving processing efficiency second. As discussed above in Section 2.1, separating
the formalism from the theory means that the formalism is stable, even as the
theory develops.
It would be beyond the scope of this chapter to give a full review of parsing
algorithms, but it is instructive to give an example. For grammars that have a
context-free backbone (every analysis can be expressed as a phrase-structure tree
plus constraints between mother and daughter nodes), it is possible to adapt the
standard parsing algorithm (Kay 1973) for context-free grammars. The basic idea
is to parse ‚Äúbottom-up‚Äù, starting by finding analyses for each token in the input,
and then finding analyses for increasingly longer sequences of tokens (called
spans), until the parser reaches the entire sentence.
For a context-free grammar, there is a finite number of nonterminal symbols,
and each span is analyzed as a subset of the nonterminals. For a feature-structure
grammar, each span must be analyzed as a set of feature structures,7 which makes
6 For an introduction, see Steedman & Baldridge (2011). For a comparison with HPSG, see Kubota

(2020), Chapter 30 of this volume.
theoretical work in HPSG, including Pollard & Sag (1994), distinguishes between fully

the algorithm more complicated. In principle, a grammar may allow an infinite
number of possible feature structures, for example if it includes recursive unary
rules. However, if we can bound the number of possible feature structures as ùê∂,
then the worst-case parsing time is proportional to ùê∂ 2ùëõ ùúå+1 , where ùúå is the maximum number of children in a phrase-structure rule (Carroll 1993: Section 3.2.3).
This is less complex than for an arbitrary grammar (which means that this class
of grammars is not Turing-complete), but ùê∂ may nonetheless be very large.
But is the number of possible feature structures bounded in implemented HPSG
grammars? For DELPH-IN grammars (see Section 3.2), the answer is yes. Assuming a system without relational constraints, the potential for unboundedness in
the number of feature structures stems from the potential for recursion in feature paths: a list is a simple example,8 and as another example, the elements on
a COMPS list also include the feature COMPS.
However, in practice, such recursive paths do not need to be considered by
the parsing algorithm. For example, selecting heads might place constraints on
their complements‚Äô subjects (e.g., in raising/control constructions), but no further than that (e.g., a complement‚Äôs complement‚Äôs subject). Similarly, while lists
that are potentially unbounded in length are used in semantic representations,
these are never involved in constraining grammaticality. The only lists that constrain grammaticality are valence lists, but in practical grammars these are never
greater than length four or five.9
When parsing real corpora, it turns out that the average-case complexity is
much better than might be expected (Carroll 1994). On the one hand, grammatical constructions do not generally combine in the worst-case way, and on the
other, when a grammar writer is confronted with multiple possible analyses for
a particular construction, they may opt for the analysis that is more efficient for
resolved feature structures and possibly underspecified feature structure descriptions. Much
computational work, by contrast, operates entirely with partially specified feature structures,
at both the level of grammar and the level of analyses licensed by the grammar. In keeping with
this tradition, we use the term ‚Äúfeature structure‚Äù to refer to both fully specified and partially
specified objects, and have no need for the term ‚Äúfeature structure description‚Äù.
8 More precisely, in the standard implementation of a list as a feature structure, the type list has
two subtypes null and non-empty-list, and non-empty-list has the features FIRST and REST,
where the value of REST is of type list. The value of REST can itself have the feature REST.
9 In part, this is because DELPH-IN does not adopt proposals like the DEPS list of Bouma, Malouf & Sag (2001). Furthermore, in many DELPH-IN grammars, including the English Resource
Grammar (ERG), the SLASH list cannot have more than one element. If an unbounded SLASH
list is required (such as to model cross-serial dependencies), the number of possible structures
might still be bounded as a function of sentence length; this would allow us to bound worstcase parsing complexity, but it will be a higher bound.

a particular parsing algorithm (Flickinger 2000). To measure the efficiency of
grammars and parsing algorithms in practice, it can be helpful to use a test suite
composed of a representative sample of sentences (Oepen & Flickinger 1998).

2.2.2 Parse ranking
Various kinds of ambiguity are well-known in linguistics (such as modifier attachment and part-of-speech assignment), to the point that examples like (1) are
stock in trade:
(1)

a. I saw the kid with the telescope.
b. Visiting relatives can be annoying.

A well-constructed grammar should be expected to return multiple parses for
each ambiguous sentence.
However, people are naturally very good at resolving ambiguity, which means
most ambiguity is not apparent, even to linguists. It is only with the development
of large-scale grammars that the sheer scale of ambiguity has become clear. For
example, (2) might seem unambiguous, but there is a second reading, where my
favorite is the topicalized object of speak, which would mean that town criers
generally speak the speaker‚Äôs favorite thing (perhaps a language) clearly. There
is also a third, even more implausible reading, where my favorite town is the
topicalized object. Such implausible readings don‚Äôt easily come to mind, and in
fact, the 2018 version of the English Resource Grammar (ERG; Flickinger 2000;
Flickinger 2011) gives a total of 21 readings for this sentence. With increasingly
long sentences, such ambiguities stack up very quickly. For (3), the first line of a
newspaper article,10 the ERG gives 35,094 readings.
(2) My favorite town criers speak clearly.
(3) A small piece of bone found in a cave in Siberia has been identified as
the remnant of a child whose mother was a Neanderthal and father was a
Denisovan, a mysterious human ancestor that lived in the region.
While exploring ambiguity can be interesting for a linguist, typical practical
applications require just one parse per input sentence and specifically the parse
that best reflects the intended meaning (or only the top few parses, in case the
one put forward as ‚Äúbest‚Äù is wrong). Thus, what is required is a ranking of the

parses, so that the application can only use the most highly-ranked parse, or the
top N parses.
Parse ranking is not usually determined by the grammar itself, because of the
difficulty of manually writing disambiguation rules.11 Typically, a statistical system is used (Toutanova et al. 2002; 2005). First, a corpus is treebanked: for each
sentence in the corpus, an annotator (often the grammar writer) chooses the
best parse, out of all parses produced by the grammar. The set of all parses for
a sentence is often referred to as the parse forest, and the selected best parse is
often referred to as the gold standard or gold parse. Given the gold parses for
the whole corpus, a statistical system is trained to predict the gold parse from a
parse forest, based on many features12 of the parse. From the example in (2), a
number of different features all influence the preferred interpretation: the likelihood of a construction (such as topicalization), the likelihood of a valence frame
(such as transitive speak), the likelihood of a collocation (such as town crier), the
likelihood of a semantic relation (such as speaking a town), and so on.
Because of the large number of possible parses, it can be helpful to prune the
search space: rather than ranking the full set of parses, ranking is restricted to
a smaller set of parses. Carefully choosing how to restrict the parser‚Äôs attention
can drastically reduce processing time without hurting parsing accuracy, as long
as the algorithm for selecting the subset includes the correct parse sufficiently
frequently. One method, called supertagging,13 exploits the fact that HPSG is a
lexicalized theory: choosing the correct lexical entry for each token brings in
rich information that can be exploited to rule out many possible parses. Thus if
the correct lexical entry can be chosen prior to parsing (e.g., on the basis of the
preceding and following words), the range of possible analyses the parser must
consider is drastically reduced. Although there is a chance that the supertagger
will predict the wrong lexical entry, using a supertagger can often improve parsing accuracy by ruling out parses that the parse-ranking model might incorrectly
rank too high. Supertagging was first applied to HPSG by Matsuzaki et al. (2007),
11 In fact, in earlier work, this task was undertaken by hand. One of the authors (Bender) had the

job of maintaining rule weights in addition to developing the Jacy grammar (Siegel, Bender
& Bond 2016) at YY Technologies in 2001‚Äì2002. No systematic methodology for determining
appropriate weights was available and the system was both extremely brittle (sensitive to any
changes in the grammar) and next to impossible to maintain.
12 In the machine-learning sense of feature, not the feature-structure sense.
13 The term supertagging, coined by Bangalore & Joshi (1999), refers to part-of-speech tagging,
which predicts a part of speech for each input token, from a relatively small set of part-ofspeech tags. Supertagging is ‚Äúsuper‚Äù in that it predicts detailed lexical entries, rather than
simple parts of speech.

building on previous work for TAG (Bangalore & Joshi 1999) and CCG (Clark &
Curran 2004). To allow multi-word expressions (such as by and large), where
the grammar assigns a single lexical entry to multiple tokens, Dridan (2013) proposes an extension of supertagging, called ubertagging, which jointly predicts
both a segmentation of the input and supertags for those segments. Dridan manages to increase parsing speed by a factor of four, while also improving parsing
accuracy.
Finally, in order to train these statistical systems, we need to first annotate a
treebank. When there are many parses for a sentence, it can be time-consuming
to select the best one. To efficiently use an annotator‚Äôs time, it can be helpful
to use discriminants: properties which hold for some parses but not for others
(Carter 1997). For example, discriminants might include whether to analyze an
ambiguous token as a noun or a verb, or where to attach a prepositional phrase.
This approach to treebanking also means that annotations can be re-used when
the grammar is updated (Oepen et al. 2004; Flickinger et al. 2017). For more on
treebanking, see Section 4.1.4.
2.2.3 Semantic dependencies
In practical applications of HPSG grammars, the full phrase-structure trees and
the full feature structures are often unwieldy, containing far more information
than is necessary for the task at hand. It is therefore often desirable to extract a
concise semantic representation.
In computational linguistics, a popular approach to semantics is to represent
the meaning of a sentence as a dependency graph, as this enables the use of
graph-based algorithms.14 Several types of dependency graph have been proposed based on Minimal Recursion Semantics (MRS; Copestake et al. 2005), with
varying levels of simplification. Oepen & L√∏nning (2006) observe that if every
predicate has a unique intrinsic argument, an MRS can be converted to a variablefree semantic representation by replacing each reference to a variable with a
reference to the corresponding predicate. They present Elementary Dependency
Structures (EDS): semantic graphs which maintain predicate-argument structure
but discard some scope information. (For many applications, scope information
is less important than predicate-argument structure.) Copestake (2009) builds
on this idea to create a more expressive graph-based representation called Dependency Minimal Recursion Semantics (DMRS), which is fully interconvertible
14 In this section, we are concerned with semantic

dependencies. For syntactic dependencies, see
Hudson (2020), Chapter 32 of this volume. Some practical applications of HPSG use syntactic
dependencies (including many applications of the Alpino grammar, discussed in Section 3.3.1).

with MRS.15 This expressivity is achieved by adding annotations on the edges to
indicate scope information. Finally, DELPH-IN MRS Dependencies (DM; Ivanova
et al. 2012) express predicate-argument structure purely in terms of the surface
tokens, without introducing any abstract predicates.
For example, the English Resource Grammar (ERG) produces the MRS representation in (4) for the sentence The cherry tree blossomed. For simplicity, we
have omitted some details, including features such as number and tense, individual constraints (ICONS), and the use of difference lists. By convention, DELPH-IN
predicates beginning with an underscore correspond to a lexical item, and have
a three-part format, consisting of a lemma, a part-of-speech tag, and (optionally)
a sense. Predicates without an initial underscore are abstract predicates. The qeq
constraints (equality modulo quantifiers) are scopal relationships, where quantifiers may possibly intervene (for details, see Copestake et al. 2005 or Koenig &
Richter 2020, Chapter 22 of this volume).

For readability, it can be easier to express an MRS in a more abstract mathematical form, as shown in (5). This is equivalent to the feature structure in (4).
15 More

precisely, for DMRS and MRS to be fully interconvertible, every predicate (except for
quantifiers) must have an intrinsic argument, and every variable must be the intrinsic argument of exactly one predicate.

INDEX : e 1
l 1 : _the_q (x 1, ‚Ñé 1, ‚Ñé 2 ) , ‚Ñé 1 QEQ l 4
l 2 : udef_q (x 2, ‚Ñé 3, ‚Ñé 4 ) , ‚Ñé 3 QEQ l 3

(5)

l 3 : _cherry_n_1 (x 2 )
l 4 : _tree_n_of (x 1 ) , compound (e 2, x 1, x 2 )
LTOP, l 5 : _blossom_v_1 (e 1, x 1 )

The corresponding DMRS representation is shown in (6). This captures all of
the information in the MRS in (5). Predicates are represented as nodes, while
semantic roles and scopal constraints are represented as directed edges, called
dependencies or links. Each dependency has two labels. The first is an argument
label, such as ARG1, ARG2, or RSTR (the restriction of a quantifier). The second
is a scopal constraint, such as QEQ,16 EQ (the linked nodes share a label in the
MRS, which is generally true for modifiers), or NEQ (the linked nodes don‚Äôt share
a label).

Finally, the corresponding DM representation is shown in (7). This is a simplified version of MRS, where all nodes are tokens in the sentence. Some abstract
predicates are dropped (such as udef_q), while others are converted to dependencies (such as compound). Some scopal information is dropped (such as EQ vs
NEQ). The label BV stands for the ‚Äúbound variable‚Äù of a quantifier, equivalent to
the RSTR/QEQ of DMRS.
BV

The existence of such dependency graph formalisms, as well as software packages to manipulate such graphs (e.g., Ivanova et al. 2012, Copestake et al. 2016,
Hershcovich et al. 2019, or PyDelphin17 ), has made it easier to use HPSG grammars in a number of practical tasks, as we will discuss in Section 4.2.
16 An

the

alternative notation is to write /H instead of /QEQ.

3 Development of HPSG resources
In this section we describe various projects that have developed computational
resources on the basis of or inspired by HPSG. As we‚Äôll discuss in Section 4 below, such resources can be used both in linguistic hypothesis testing as well as
in various practical applications. The intended purpose of the resources influences the form that they take. The CoreGram Project (Section 3.1) and Babel
(Section 3.3.3) primarily target linguistic hypothesis testing, the Alpino and Enju
parsers (Section 3.3.1 and 3.3.2) primarily target practical applications, and the
DELPH-IN Consortium (Section 3.2) attempts to balance these two goals.

3.1 CoreGram
The CoreGram18 Project aims to produce large-scale HPSG grammars, which
share a common ‚Äúcore‚Äù grammar (M√ºller 2015). At the time of writing, large
grammars have been produced for German (M√ºller 2007), Danish (M√ºller & √òrsnes
2013), Persian (M√ºller & Ghayoomi 2010), Maltese (M√ºller 2009), and Mandarin
(M√ºller & Lipenkova 2013). Smaller grammars are also available for English, Yiddish, Spanish, French, and Hindi.
All grammars are implemented in the TRALE system (Meurers et al. 2002;
Penn 2004), which accommodates a wide range of technical devices proposed in
the literature, including phonologically empty elements, relational constraints,
implications with complex antecedents, and cyclic feature structures. It also accomodates macros and an expressive morphological component. Melnik (2007)
observes that, compared to other platforms like the LKB (see Section 3.2 below),
this allows grammar engineers to directly implement a wider range of theoretical
proposals.
An important part of CoreGram is the sharing of grammatical constraints
across grammars. Some general constraints hold for all grammars, while others hold for a subset of the grammars, and some only hold for a single grammar.
M√ºller (2015) describes this as a ‚Äúbottom-up approach with cheating‚Äù (p. 43): the
aim is to analyze each language on its own terms (hence ‚Äúbottom-up‚Äù), but to
re-use analyses from existing grammars if possible (hence ‚Äúwith cheating‚Äù). The
use of a core set of constraints is motivated not just for practical reasons, but also
for theoretical ones. By developing multiple grammars in parallel, analyses can
be improved by cross-linguistic comparison. The constraints encoded in the core
grammar can be seen as a hypothesis about the structure of human language, as
18 https://hpsg.hu-berlin.de/Projects/CoreGram.html

we will discuss in Section 4.1.1.
CoreGram grammar development aims to incrementally increase coverage of
each language. To measure progress, grammars are evaluated against test suites:
collections of sentences each annotated with a grammaticality judgment (Oepen
et al. 1997; M√ºller 2004b). This allows a grammarian to check for unexpected side
effects when modifying a grammar and to avoid situations when implementing
an analysis of one phenomenon would break the analysis of another phenomenon. This is particularly important when modifying a constraint that is used
by several grammars. To help achieve these aims, grammar development is supported by a range of software tools, including the test suite tool [incr tsdb()] (Oepen
2001; see also Section 3.2), and the graphical debugging tool Kahina (Dellert et al.
2010; 2013).

3.2 The DELPH-IN Consortium
The DELPH-IN19 Consortium was established in 2001 to facilitate the development of large-scale, linguistically motivated HPSG grammars for multiple languages, in tandem with the software required for developing them and deploying them in practical applications. At the time when DELPH-IN was founded, the
ERG (Flickinger 2000; Flickinger 2011) had already been under development for
8 years, and the Verbmobil project (Wahlster 2000) had also spurred the development of grammars for German (GG; M√ºller & Kasper 2000; Crysmann 2003) and
Japanese (Jacy; Siegel, Bender & Bond 2016). Project DeepThought (Callmeier,
Eisele, Sch√§fer & Siegel 2004) was exploring methodologies for combining deep
and shallow processing in practical applications across multiple languages. This
inspired the development of the LinGO Grammar Matrix (Bender, Flickinger &
Oepen 2002), which began as a core grammar, consisting of constraints hypothesized to be cross-linguistically useful, abstracted out of the ERG with reference
to Jacy and GG. The goal of the Grammar Matrix is to serve as a starting point
for the development of new grammars, making it easy to reuse what has been
learned in the development of existing grammars. In the years since, it has been
extended to include ‚Äúlibraries‚Äù of analyses of cross-linguistically variable phenomena (e.g., Drellishak 2009; Bender et al. 2010).
DELPH-IN provides infrastructure (version control repositories, mailing lists,
annual meetings) and an emphasis on open-source distribution of resources, both
of which support the collaboration of a global network of researchers working on
19 DELPH-IN

stands for DEep Linguistic Processing in HPSG INitiative; see http://www.delph-in.
net 

interoperable components. Such components include repositories of linguistic
knowledge, that is, both grammars and meta-grammars (including the Matrix
and CLIMB, Fokkens 2014); processing engines that apply that knowledge for
parsing and generation (discussed further below); software for supporting the
development of grammar documentation (e.g., Hashimoto et al. 2008), software
for creating treebanks (Oepen et al. 2004; Packard 2015; see also Section 4.1.4
below), parse ranking models trained on these treebanks (Toutanova et al. 2005;
see also Section 2.2.2 above), and software for robust processing, i.e. using the
knowledge encoded in the grammars to return analyses for sentences even if the
grammar deems them ungrammatical (Zhang & Krieger 2011; Buys & Blunsom
2017; Chen et al. 2018).
A key accomplishment of the DELPH-IN Consortium is the standardization of
a formalism for the declaration of grammars (Copestake 2002a), a formalism for
the semantic representations (Copestake et al. 2005), and file formats for the storage and interchange of grammar outputs (e.g., parse forests, as well as the results
of treebanking; Oepen 2001; Oepen et al. 2004). These standards facilitate the development of multiple different parsing and generation engines which can all
process the same grammars, including, so far, the LKB (Copestake 2002b), PET
(Callmeier 2000), ACE,20 and Agree (Slayden 2012); of multiple software systems
for processing bulk grammar output, like [incr tsdb()] (Oepen 2001), art,21 and PyDelphin22 ; and of multilingual downstream systems which can be adapted to
additional languages by plugging in different grammars. These tools and standards have in turn helped support a thriving community of users who furthermore accumulate and share information about best practices. Melnik (2007: 234)
credits this community and the information it shares as a key factor that makes
the grammar engineering with the DELPH-IN ecosystem more accessible to HPSG
linguists, compared to other platforms like TRALE (see Section 3.1 above).
The DELPH-IN community maintains research interests in both linguistics and
practical applications. The focus on linguistics means that DELPH-IN grammarians strive to create grammars which capture linguistic generalizations and model
grammaticality. This, in turn, leads to grammars with lower ambiguity than one
finds with treebank-trained grammars and, importantly, grammars which produce well-formed strings in generation. The focus on practical applications leads
to several kinds of additional research goals. Practical applications require robust
processing, which in turn requires methods for handling unknown words (e.g.,
20 http://sweaglesw.org/linguistics/ace/,


methods for managing extra-grammatical mark-up in text
such as in Wikipedia pages (e.g., Flickinger et al. 2010b), and strategies for processing inputs that are ungrammatical, at least according to the grammar (e.g.,
Zhang & Krieger 2011; see also Section 4.2.3). Processing large quantities of text
motivates performance innovations, such as supertagging or ubertagging (e.g.,
Matsuzaki et al. 2007; Dridan 2013; see also Section 2.2.2). to speed up processing times. Naturally occurring text can include very long sentences which can
run up against processing limits. Supertagging helps here, too, but other strategies include sentence chunking, which is the task of breaking a long sentence
into smaller ones without loss of meaning (Muszy≈Ñska 2016). Working with realworld text (rather than curated test suites designed for linguistic research only)
requires the integration of external components such as morphological analyzers (e.g., Marimon 2013) and named entity recognizers (e.g., Waldron et al. 2006;
Sch√§fer et al. 2008). As described in Section 2.2.2, working with real-world applications requires parse ranking (e.g., Toutanova et al. 2005), and similarly ranking
of generator outputs (known as realization ranking; e.g., Velldal 2009). Finally,
research on embedding broad-coverage grammars in practical applications inspires work towards making sure that the semantic representations can serve as
a suitable interface for external components (e.g., Flickinger et al. 2005). These
efforts are also valuable from a strictly linguistic point of view, i.e. one not concerned with practical applications. First, the broader the coverage of a grammar,
the more linguistic phenomena it can be used to explore. Second, external constraints on the form of semantic representations provide useful guide points in
the development of semantic analyses.

3.3 Other HPSG and HPSG-inspired broad-coverage grammars
3.3.1 Alpino
Alpino23 is a broad-coverage grammar of Dutch (Bouma, van Noord & Malouf
2001; van Noord & Malouf 2005; van Noord 2006). The main motivation is practical: to provide coverage and accuracy comparable to state-of-the-art parsers for
English. Nonetheless, it also includes theoretically interesting analyses, such as
for cross-serial dependencies (Bouma & van Noord 1998). In addition to using
hand-written rules, lexical information (such as subcategorization frames) has
also been extracted from two existing lexicons, Celex (Baayen et al. 1995) and
Parole (Kruyt & Dutilh 1997).
23 http://www.let.rug.nl/vannoord/alp/Alpino/,

Alpino produces syntactic dependency graphs, following the annotation format of the Spoken Dutch Corpus (Oostdijk 2000). These dependencies are constructed directly in the feature-structure formalism, exploiting the fact that a
feature structure can be formalized as a directed acyclic graph. Each lexical entry encodes a partial dependency graph, and these graphs are composed through
phrase structure rules to give a dependency graph for a whole sentence.
Although these dependencies differ from the semantic dependencies discussed
in Section 2.2.3, a common motivation is to make the representations easier to
use in practical applications. To harmonize with other computational work on
dependency parsing, Bouma & van Noord (2017) have also produced a mapping
from this format to Universal Dependencies (UD; Nivre et al. 2016), as discussed
in Section 4.1.4 below. Alpino uses a statistical model trained on a dependency
treebank, and in fact the same statistical model can be used in both parsing and
generation (de Kok et al. 2011).
3.3.2 Enju
Enju24 (Miyao et al. 2005) is a broad-coverage grammar of English, semi-automatically
acquired from the Penn Treebank (Marcus et al. 1993). This approach aims to reduce the cost of writing a grammar by leveraging existing resources. The basic
idea is that, by viewing Penn Treebank trees as partial specifications of HPSG
analyses, it is possible to infer lexical entries.
Miyao et al. converted the relatively flat trees in the Penn Treebank to binarybranching trees, and percolated head information through the trees. They also
had to convert analyses for certain constructions, including subject-control verbs,
auxiliary verbs, coordination, and extracted arguments. Each converted tree can
then be combined with a small set of hand-written HPSG schemata, to induce a
lexical entry for each word in the sentence.
Development of Enju has focused on performance in practical applications,
and the grammar is supported by an efficient parser (Tsuruoka et al. 2004; Matsuzaki et al. 2007), using a probabilistic model for feature structures (Miyao &
Tsujii 2008). Enju has been used in a variety of NLP tasks, as will be discussed in
Section 4.2.2.
3.3.3 Babel
Babel is a broad-coverage grammar of German (M√ºller 1996; 1999). One interesting feature of this grammar is that it makes extensive use of discontinuous con24 http://www.nactem.ac.uk/enju/,

stituents (M√ºller 2004a). Although this makes the worst-case parsing complexity
much worse, parsing speed doesn‚Äôt seem to suffer in practice. This mirrors the
findings of Carroll (1994), discussed in Section 2.2.1 above.

4 Deployment of HPSG resources
There are several different ways in which computational resources based on
HPSG are used. In Section 4.1, we first consider applications furthering linguistic research, including both language documentation and linguistic hypothesis
testing. Then, in Section 4.2, we consider applications outside of linguistics.

4.1 Language documentation and linguistic hypothesis testing
As described by M√ºller (1999), Bender (2008), and Bender et al. (2011), grammar
engineering ‚Äî that is, the building of grammars in software ‚Äî is an essential technique for testing linguistic hypotheses at scale. By ‚Äúat scale‚Äù, we mean both
against large quantities of data and as integrated models of language that handle
multiple phenomena at once. In this section, we review how this is done in the
CoreGram and Grammar Matrix projects for cross-linguistic hypothesis testing,
and in the AGGREGATION project in the context of language documentation.25
4.1.1 CoreGram
As described in Section 3.1, the CoreGram project develops grammars for a diverse set of languages, and shares constraints across grammars in a bottom-up
fashion, so that more similar languages share more constraints. There are constraints shared across all of the grammars in the project which can be seen as a
hypothesis about properties shared by all languages. Whenever the CoreGram
project expands to cover a new language, it can be seen as a test of this hypothesis.
For example, the most general constraint set allows a language to have V2
word order (as exemplified by Germanic languages), but rules out verb-penultimate word order, as discussed by M√ºller (2015) (see also M√ºller 2020a, Chapter 10
25 Grammar engineering isn‚Äôt specific to HPSG and in fact has a history going back to at least the

early 1960s (Kay 1963; Zwicky et al. 1965; Petrick 1965; Friedman et al. 1971) and modern work
in grammar engineering includes work in many different frameworks, such as Lexical Functional Grammar (Butt et al. 1999), Combinatory Categorial Grammar (Baldridge et al. 2007),
Grammatical Framework (Ranta 2009), and others. For reflections on grammar engineering
for linguistic hypothesis testing in LFG, see Butt et al. (1999) and King (2016).


of this volume). It also includes constraints for argument structure and linking
(see Wechsler, Koenig & Davis 2020, Chapter 9 of this volume), as well as for
information structure (see De Kuthy 2020, Chapter 23 of this volume).
4.1.2 Grammar Matrix
As noted in Section 3.2, the LinGO Grammar Matrix (Bender et al. 2002; 2010) was
initially developed in the context of Project DeepThought with the goal of speeding up the development of DELPH-IN-style grammars for additional languages. It
consists of a shared core grammar and a series of ‚Äúlibraries‚Äù of analyses for crosslinguistically variable phenomena. Both of these constitute linguistic hypotheses:
the constraints are hypothesized to be cross-linguistically useful. However, in
the course of developing grammars based on the Matrix for specific languages,
it is not uncommon to find reasons to refine the core grammar. The libraries,
in turn, are intended to cover the attested range of variation for the phenomena they model. Languages that are not covered by the analyses in the libraries
provide evidence that the libraries need to be extended or refined.
Grammar Matrix grammar development is less tightly coordinated than that
of CoreGram (see Section 3.1): in the typical use case, grammar developers start
from the Grammar Matrix, but with their own independent copy of the Matrix
core grammar. This impedes somewhat the ability of the Matrix to adapt to the
needs of various languages (unless grammar developers report back to the Matrix
developers). On the other hand, the Matrix libraries represent an additional kind
of linguistic hypothesis testing: each library on its own represents one linguistic
phenomenon, but the libraries must be interoperable with each other. This is the
cross-linguistic analogue of how monolingual implemented grammars allow linguists to ensure that analyses of different phenomena are interoperable (M√ºller
1999: 439‚Äì440; Bender 2008): the Grammar Matrix customization system allows
its developers to test cross-linguistic libraries of analyses for interactions with
other phenomena (Bender et al. 2011; Bender 2016). Without computational support (i.e. a computer keeping track of the constraints that make up each analysis,
compiling them into specific grammars, and testing those grammars against test
suites), this problem space would be too complex for exploration.
4.1.3 AGGREGATION
In many ways, the most urgent need for computational support for linguistic hypothesis testing is the description of endangered languages. Implemented grammars can be used to process transcribed but unglossed text in order to find rel-

evant examples more quickly, both of phenomena that have already been analyzed and of phenomena that are as yet not well-understood.26 Furthermore,
treebanks constructed from implemented grammars can be tremendously valuable additions to language documentation (see Section 4.1.4 below). However,
the process of building an implemented grammar is time-consuming, even with
the start provided by a multilingual grammar engineering project like CoreGram,
ParGram (Butt et al. 2002; King et al. 2005), the GF Resource Grammar Library
(Ranta 2009), or the Grammar Matrix.
This is the motivation for the AGGREGATION27 project, which starts from
two observations: (1) descriptive linguists produce extremely rich annotations
on data in the form of interlinear glossed text (IGT); and (2) the Grammar Matrix‚Äôs libraries are accessed through a customization system which elicits a grammar specification in the form of a series of choices describing either high-level
typological properties or specific constraints on lexical classes and lexical rules.
The goal of AGGREGATION is to automatically produce such grammar specifications on the basis of information encoded in IGT, to be used by the Grammar
Matrix customization system to produce language-particular grammars. AGGREGATION uses different approaches for different linguistic subsystems. For example, it learns morphotactics by observing morpheme order in the training data,
and how to group affixes together into position classes based on measures of overlap of stems they attach to (Wax 2014; Zamaraeva et al. 2017). For many kinds of
syntactic information, it leverages syntactic structure projected from the translation line (English, easily parsed with current tools) through the gloss line (which
facilitates aligning the language and translation lines) to the language line (Xia &
Lewis 2007; Georgi 2016). Using this projected information, the AGGREGATION
system can detect case frames for verbs, word order patterns, etc. (Bender et al.
2013; Zamaraeva et al. 2019).28
4.1.4 Treebanks and sembanks
Annotated corpora are a particularly valuable type of resource that can be derived from HPSG grammars. Two important kinds are treebanks and sembanks.
A treebank is a collection of text where each sentence is associated with a syn26 This methodology of using an implemented grammar as a sieve to sift the interesting examples

out of corpora is demonstrated for English by Baldwin et al. (2005).
accessed 16 August 2019.
28 The TypeGram project (Hellan & Beermann 2014) is in a similar spirit. TypeGram provides
methods of creating HPSG grammars by encoding specifications of valence and inflection in
particularly rich IGT and then creating grammars based on those specifications.

tactic representation. A sembank has semantic representations (in some cases in
addition to the syntactic ones). Treebanks and sembanks can be used for linguistic research, as the analyses allow for more detailed structure-based searches for
phenomena of interest (Rohde 2005; Ghodke & Bird 2010; Kouylekov & Oepen
2014).29 In the context of language documentation and description, searchable
treebanks can also be a valuable addition, helping readers connect prose descriptions of linguistic phenomena to multiple examples in the corpus (Bender et al.
2012). In natural language processing, treebanks and sembanks are critical source
material for training parsers (see Sections 2.2.2 and 4.2.3).
Traditional treebanks are created by doing a certain amount of automatic processing on corpus data, including possibly chunking or context-free grammar
parsing, and then hand-correcting the result (Marcus et al. 1993; Banarescu et
al. 2013). While this approach is a means to encode human insight about linguistic structure for later automatic processing, it is both inefficient and potentially error-prone. The Alpino project (van der Beek et al. 2002; see also Section 3.3.1 above) addresses this by first parsing the text with a broad-coverage
HPSG-inspired grammar of Dutch and then having annotators select among the
parses. The selection process is facilitated by allowing the annotators to mark
constituent boundaries and to mark lexical entries as correct, possibly correct,
or wrong. These constraints reduce the search space for the parser and consequently also the range of analyses the annotator has to consider before choosing
the best one. A facility for adding one-off lexical entries to handle misspellings,
for example, helps increase grammar coverage. Disambiguation is handled with
the aid of discriminants, as discussed in Section 2.2.2 above. Finally, the annotators may further edit analyses deemed insufficient. Though the underlying
grammar is based on HPSG, the treebank stores dependency graphs instead. The
Alpino parser was similarly used to construct the Lassy Treebanks of written
Dutch (van Noord et al. 2013). In more recent work, these dependency representations have been mapped to the Universal Dependencies (UD) annotation
standards (Nivre et al. 2016) to produce a UD treebank for Dutch (Bouma & van
Noord 2017).
The Redwoods project (Oepen et al. 2004) also produces grammar-driven treebanks, in this case for English and without any post-editing of analyses.30 As
with Alpino, this is done by first parsing the corpus with the grammar and calcu29 The WeSearch interface of Kouylekov & Oepen (2014) can be accessed at http://wesearch.delph-

in.net/deepbank/search.jsp (accessed 16 August 2019).
are also Redwoods-style treebanks for other languages, including the Hinoki Treebank
of Japanese (Bond et al. 2004) and the Tibidabo Treebank of Spanish (Marimon 2015).

ating the discriminants for each parse forest. After annotation, the treebanking
software stores not only the final full HPSG analysis that was selected, but also
the decisions the annotator made about each discriminant. Thus when the grammar is updated, for example to refine the semantic representations, the corpus
can be reparsed and the decisions replayed, leaving only a small amount of further annotation work to be done to handle any additional ambiguity introduced
by the grammar update. The activity of treebanking in turn provides useful insight into grammatical analyses, including sources of spurious ambiguity and
phenomena that are not yet properly handled, and thus informs and spurs on
further grammar development. A downside to strictly grammar-based treebanking is that only items for which the grammar finds a reasonable parse can be
included in the treebank. For many applications, this is not a drawback, so long
as there are sufficient and sufficiently varied sentences that do receive analyses.
Finally, there are also automatically annotated treebanks. These are not as
reliable as manually annotated treebanks, but they can be considerably larger.
WikiWoods31 covers 55 million sentences of English (900 million tokens). It was
produced by Flickinger et al. (2010a) and Solberg (2012) from the July 2008 dump
of the full English Wikipedia, using the ERG and PET, with parse ranking trained
on the manually treebanked subcorpus WeScience (Ytrest√∏l et al. 2009). As with
the Redwoods treebanks, WikiWoods is updated with each release of the ERG.

4.2 Downstream applications
In this section, we discuss the use of HPSG grammars for practical tasks. There is
a large number of applications, and we focus on several important ones here. In
Section 4.2.1, we cover educational applications where a grammar is used directly.
In Section 4.2.2, we cover cases where a grammar is used to provide features to
help solve tasks in Natural Language Processing (NLP). Finally, in Section 4.2.3,
we cover situations where a grammar is used to provide data for machine learning systems.32
4.2.1 Education
Precise syntactic analyses can be useful in language teaching, in order to automatically identify errors and give feedback to the student. In order to model

common mistakes, a grammar can be extended with so-called mal-rules. A malrule is like a normal rule, in that it licenses a construction, and can be treated the
same during parsing. However, given a parse, the presence of a mal-rule indicates that the student needs to be given feedback (Bender et al. 2004; Flickinger
& Yu 2013; Morgado da Costa et al. 2016). A large-scale system implementing this
kind of computer-aided teaching has been developed by the Education Program
for Gifted Youth at Stanford University, using the ERG (Suppes et al. 2014). This
system has reached tens of thousands of elementary and middle school children,
and has been found to improve the school results of underachieving children.
Another way to use an implemented grammar is to automatically produce
teaching materials. Given a semantic representation, a grammar can generate
one or more sentences. Flickinger (2017) uses the ERG to produce practice exercises for a student learning first-order logic. For each exercise, the student is
presented with an English sentence and is supposed to write down the corresponding first-order logical form. By using a grammar, the system can produce
syntactically varied questions and automatically evaluate the student‚Äôs answer.
4.2.2 NLP tasks
Much NLP work focuses on specific tasks, where a system is presented with some
input and required to produce an output, with a clearly-defined metric to determine how well the system performs. HPSG grammars have been used in a range
of such tasks, where the syntactic and semantic analyses provide useful features.
Information retrieval is the task of finding relevant documents for a given
query. For example, Sch√§fer et al. (2011) present a tool for searching the ACL
Anthology, using the ERG. Information extraction is the task of identifying useful facts in a collection of documents. For example, Reiplinger et al. (2012) aim
to identify definitions of technical concepts from English text, in order to automatically construct a glossary. They find that using the ERG reduces noise
in the candidate definitions. Miyao et al. (2008) aim to identify protein-protein
interactions in the English biomedical literature, using Enju.
For these tasks, some linguistic phenomena are particularly important, such
as negation and hedging (including adverbs like possibly, modals like may, and
verbs of speculation like suggest). When it comes to identifying facts asserted
in a document, a clause that has been negated or hedged should be treated with
caution. MacKinlay et al. (2012) consider the biomedical domain, evaluating on
the BioNLP 2009 Shared Task (Kim et al. 2009), where they outperform previous approaches for negation, but not for speculation. Velldal et al. (2012) consider negation and speculation in biomedical text, evaluating on the CoNLL 2010

Shared Task (Farkas et al. 2010), where they outperform previous approaches.
Packard et al. (2014) propose a general-purpose method for finding the scope of
negation in an MRS, evaluating on the *SEM 2012 Shared Task (Morante & Blanco
2012). They find that transforming the output of the ERG with a relatively simple
set of rules achieves high performance on this English dataset, and combining
this approach with a purely statistical system outperforms previous approaches.
Zamaraeva et al. (2018) use the ERG for negation detection and then use that
information to refine the (machine-learning) features in a system that classifies
English pathology reports, thereby improving system performance. A common
finding from these studies is that a system using the output of the ERG tends to
have high precision (items identified by the system tend to be correct) but low
recall (items are often overlooked by the system). One reason for low recall is
that the grammar does not cover all sentences in natural text. As we will see in
Section 4.2.3, recent work on robust parsing may help to close this coverage gap.
Negation resolution is also included in Oepen et al.‚Äôs (2017) Shared Task on Extrinsic Parser Evaluation. As mentioned in Section 2.2.3, dependency graphs can
provide a useful tool in NLP tasks, and this shared task aims to evaluate the use of
dependency graphs (both semantic and syntactic) for three downstream applications: biomedical information extraction, negation resolution, and fine-grained
opinion analysis. Some participating teams use DM dependencies(Schuster et al.
2017; Chen et al. 2017). The results of this shared task suggest that, compared to
other dependency representations, DM is particularly useful for negation resolution.
Another task where dependency graphs have been used is summarization.
Most existing work on this task focuses on so-called extractive summarization:
given an input document, a system forms a summary by extracting short sections
of the input. This is in contrast to abstractive summarization, where a system
generates new text based on the input document. Extractive summarization is
limited, but widely used because it is easier to implement. However, Fang et al.
(2016) show how a wide-coverage grammar like the ERG makes it possible to
implement an abstractive summarizer with state-of-the-art performance. After
parsing the input document into logical propositions, the summarizer prunes the
set of propositions using a cognitively inspired model. A summary is then generated based on the pruned set of propositions. Because no text is directly extracted
from the input document, it is possible to generate a more concise summary.
Finally, no discussion of NLP tasks would be complete without including machine translation. A traditional grammar-based approach uses three grammars: a
grammar for the source language, a grammar for the target language, and a trans-


fer grammar, which converts semantic representations for the source language
to semantic representations for the target language (Oepen et al. 2007; Bond et
al. 2011). Translation proceeds in three steps: parse the source sentence, transfer the semantic representation, and generate a target sentence. The transfer
grammar is needed both to find appropriate lexical items and also to convert semantic representations when languages differ in how an idea might be expressed.
The difficulty in writing a transfer grammar that is robust enough to deal with
arbitrary input text means that statistical systems might be preferred. Horvat
(2017) explores the use of statistical techniques, skipping over the transfer stage:
a target-language sentence is generated directly from a semantic representation
for the source language. Goodman (2018) explores the use of statistical techniques within the paradigm of parsing, transferring, and generating.
4.2.3 Data for machine learning
In Section 4.2.2, we described how HPSG grammars can be directly incorporated
into NLP systems. Another use of HPSG grammars in NLP is to generate data on
which a statistical system can be trained.
For example, one limitation of using an HPSG grammar in an NLP system is
that the grammar is unlikely to cover all sentences in the data (Flickinger et al.
2012). One way to overcome this coverage gap is to train a statistical system to
produce the same output as the grammar. The idea is that the trained system
will be able to generalize to sentences that the grammar does not cover. Oepen
et al. (2014), Oepen et al. (2015), and Oepen et al. (2019) present shared tasks
on semantic dependency parsing, including both DM dependencies and Enju
predicate-argument structures. As of 2015, the best-performing systems in these
shared tasks could already produce dependency graphs almost as accurately as
grammar-based parsers (for sentences where the grammar has coverage). Similarly, Buys & Blunsom (2017) develop a parser for EDS and DMRS which performs
almost as well as a grammar-based parser, but has full coverage, and can run 70
times faster.
In fact, in more recent work, the difference in performance has been effectively
closed. Chen et al. (2018) consider parsing to EDS and DMRS graphs, and actually achieve slightly higher accuracy with their system, compared to a grammarbased parser. Unlike the previous statistical approaches, Chen et al. do not just
train on the desired dependency graphs, but also use information in the phrasestructure trees. They suggest that using this information allows their system to
learn compositional rules mirroring composition in the grammar, which thereby
allows their system to generalize better.

Another application of HPSG-derived dependency graphs is for distributional
semantics. Here, the aim is to learn the meanings of words from a corpus, exploiting the fact that the context of a word tells us something about its meaning.
This is known as the distributional hypothesis, an idea with roots in American
structuralism (Harris 1954) and British lexicology (Firth 1951; 1957). Most work
on distributional semantics learns a vector space model, where the meaning of
each word is represented as a point in a high-dimensional vector space (for an
overview, see Erk 2012 and Clark 2015). However, Emerson (2018) argues that
vector space models cannot capture various aspects of meaning, such as logical
structure, and phenomena like polysemy. Instead, Emerson presents a distributional model which can learn truth-conditional semantics, using a parsed corpus
like WikiWoods (see Section 4.1.4). This approach relies on the semantic analyses given by a grammar, as well as the infrastructure to parse a large amount of
text.
Finally, there are also applications which use grammars not to parse, but to
generate. Kuhnle & Copestake (2018) consider the task of visual question answering, where a system is presented with an image and a question about the
image, and must answer the question. This task requires language understanding, reference resolution, and grounded reasoning, in a way that is relatively
well-defined. However, for many existing datasets, there are biases in the questions which mean that high performance can be achieved without true language
understanding. For this reason, there is increasing interest in artificial datasets,
which are controlled to make sure that high performance requires true understanding. Kuhnle & Copestake present ShapeWorld, a configurable system for
generating artificial data. The system generates an abstract representation of a
scene (colored shapes in different configurations), and then generates an image
and a caption based on this representation. The use of a broad-coverage grammar
is crucial in allowing the system to be configurable and scale across a variety of
syntactic constructions.

5 Linguistic insights
In Section 4.1 above, we described multiple ways in which computational methods can be used in the service of linguistic research, especially in testing linguistic hypotheses. Here, we highlight a few ways in which grammar engineering
work in HPSG has turned up linguistic insights that had not previously been


5.1 Ambiguity
As discussed in Section 2.2.2, the scale of ambiguity has become clear now that
broad-coverage precision grammars are available. By taking both coverage and
precision seriously, it is possible to investigate it on a large scale, quantifying
the sources of ambiguity and the information needed to resolve it. For example,
Toutanova et al. (2002; 2005) found that in the Redwoods treebank (3rd Growth),
roughly half of the ambiguity was lexical, and half syntactic. They also showed
how combining sources of information (such as both semantic and syntactic information) is important for resolving ambiguity, and argue that using multiple
kinds of information in this way is consistent with probabilistic approaches in
psycholinguistics.

5.2 Long-tail phenomena
One of the strengths of HPSG as a theoretical framework is that it allows for
the analysis of both ‚Äúcore‚Äù and ‚Äúperipheral‚Äù phenomena within a single, integrated model. Indeed, by implementing large-scale grammars across a range
of languages, it becomes possible to investigate the extent to which a particular
phenomenon should be considered ‚Äúcore‚Äù, ‚Äúperipheral‚Äù, or something in between
(M√ºller 2014).
In fact, when working with actual data and large-scale grammars, it quickly
becomes apparent just how long the long-tail of ‚Äúperipheral‚Äù phenomena is. Furthermore, the sustained development of broad-coverage linguistic resources makes
it possible to bring into view more and more low-frequency phenomena (or lowfrequency variations on relatively high-frequency phenomena). A case in point
is the range of raising and control valence frames found in the ERG (Flickinger
2000; Flickinger 2011). As of the 2018 release, the ERG includes over 60 types
for raising and control predicates, including verbs, adjectives, and nouns, many
of which are not otherwise discussed in the syntactic literature. These include
such low-frequency types as the one for incumbent, which requires an expletive
it subject, an obligatory (up)on PP complement, and an infinitival VP complement, and which establishes a control relation between the object of on and the
VP‚Äôs missing subject

similar reflections from the point of view of LFG, see King (2016).
thanks to Dan Flickinger for this example.

5.3 Analysis-order effects
Grammar engineering means making analyses specific and then being able to
build on them. This has both benefits and drawbacks: on the one hand, it means
that additional grammar engineering work can build directly on the results of
previous work. It also means that any additional grammar engineering work is
constrained by the work it is building on. Fokkens (2014) observes this phenomenon and notes that it introduces artifacts: the form an implemented grammar
takes is partially the result of the order in which the grammar engineer considered phenomena to implement. This is probably also true for non-computational
work, as theoretical ideas developed with particular phenomena (and, indeed,
languages) in mind influence the questions with which researchers approach additional phenomena. Fokkens proposes that the methodology of meta-grammar
engineering can be used to address this problem: using her CLIMB methodology, rather than deciding between analyses of a given phenomenon without input from later-studied phenomena, the grammar engineer can maintain multiple
competing analyses through time and break free, at least partially, of the effects
of the timeline of grammar development. The central idea is that the grammar
writer develops a meta-grammar, like the Grammar Matrix customization system
(see Section 4.1.2), but for a single language. This customization system maintains alternate analyses of particular phenomena which are invoked via grammar specifications so the different versions of the grammar can be compiled and
tested.

6 Summary
In this chapter, we have attempted to illuminate the landscape of computational
work in HPSG. We have discussed how HPSG as a theory supports computational
work, described large-scale computational projects that use HPSG, highlighted
some applications of implemented grammars in HPSG, and explored ways in
which computational work can inform linguistic research. This field is very active and our overview is necessarily incomplete. Nonetheless, it is our hope that
the pointers and overview provided in this chapter will serve to help interested
readers connect with ongoing research in computational linguistics using HPSG.
